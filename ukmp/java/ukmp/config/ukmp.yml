# HTTP-specific options
http:

  port: 8080
  adminPort: 8081

  rootPath: /service/*

  requestLog:
    console:
      enabled: false
    
    file:
      enabled: true
      currentLogFilename: log/access.log
      archive: true
      archivedLogFilenamePattern: log/access-%d.log

# Logging
logging:

  level: INFO

  loggers:
    # Set debug logging for our code
    "uk.co.flax": TRACE
    
  console:
    enabled: false
    
  file:
    enabled: true
    
    # The file to which statements will be logged.
    currentLogFilename: log/ukmp.log

    # If true, log files are rotated and archived.
    archive: true

    # When the log file rolls over, the file will be archived to
    # app-2012-03-15.log, example.log will be truncated,
    # and new statements written to it.
    # To automatically gzip archive, add .gz to end of filename
    #
    # If archive is true, this must be specified.
    archivedLogFilenamePattern: log/api-%d.log


# Solr configuration
solr:

  # The base URL for the solr server.
  baseUrl: http://localhost:8983/solr/
  
  # The default query handler
  queryHandler: /morris
  
  # The facet queries, with display labels
  facetQueryFields:
    created_at:
      "[NOW/DAY-1DAYS TO NOW/DAY]": 'Today'
      "[NOW/DAY-7DAYS TO NOW/DAY]": 'This week'
      "[NOW/DAY-30DAYS TO NOW/DAY]": 'This month'
      "[NOW/DAY-365DAYS TO NOW/DAY]": 'This year'
      "[NOW/DAY-730DAYS TO NOW/DAY]": '2 years'
      
    retweet_count:
       "0" : "No retweets"
       "[1 TO 10]" : "1 - 10"
       "[11 TO 100]" : "11 - 100"
       "[101 TO 1000]" : "101 - 1000"
       "[1000 TO *]" : "Over 1000"

    favorite_count:
       "0" : "No favorites"
       "[1 TO 10]" : "1 - 10"
       "[11 TO 100]" : "11 - 100"
       "[101 TO 1000]" : "101 - 1000"
       "[1000 TO *]" : "Over 1000"

  # Labels to use for the facets, when displayed
  facetLabels:
    party: "Party"
    organization_ner: "Organisation"
    person_ner: "Person"
    location_ner: "Location"
    ent_mentions_full_name: "Mentions"
    ent_urls: "URL"
    place_country: "Country"
    place_full_name: "Place"
    user_full_name: "User name"
    created_at: "Created"
    retweet_count: "Retweet count"
    favorite_count: "Favourite count"
    
  # Config for the terms component
  terms:
    # The request handler for the terms component
    handler: /query
    # The field to use
    field: text
    # The number of terms to fetch
    limit: 75
    # The sort order to use - either count or index
    sortOrder: count
    # The size of the batch to fetch
    batchSize: 1000
    # The filters to apply
    filters: [
      "created_at:[NOW/DAY-1DAYS TO NOW/DAY]"
    ]
    # The stopwords file
    stopWordsFile: config/terms_stopwords.txt
    # The delay between updates (in minutes)
    refreshMinutes: 10
    

# The Stanford NLP configuration
stanford:

  # Java properties for entity extraction - need to be wrapped up this way to work properly
  entityProperties:
    # The NER classifier to use - taken from the stanford-nlp-models.jar
    loadClassifier: /edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz

  # Java properties for sentiment analysis
  sentimentProperties:
    annotators: "tokenize, ssplit, parse, sentiment"
